{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3ec614-c79d-4ee9-a8df-652c1dc3bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'ESC' to quit.\n",
      "New person detected: Person_1\n",
      "Captured image: captured_faces\\Person_1 (Female)_20241205_090909_0.jpg\n",
      "Recognized: Person_1\n",
      "Captured image: captured_faces\\Person_1 (Male)_20241205_090915_1.jpg\n",
      "Recognized: Person_1\n",
      "Captured image: captured_faces\\Person_1 (Female)_20241205_090920_2.jpg\n",
      "Recognized: Person_1\n",
      "Captured image: captured_faces\\Person_1 (Female)_20241205_090926_3.jpg\n",
      "Recognized: Person_1\n",
      "Captured image: captured_faces\\Person_1 (Male)_20241205_090941_4.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Step 1: Load Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Step 2: Gender Prediction Helper Function\n",
    "def predict_gender(face_image):\n",
    "    # Dummy function for gender prediction (replace with actual model for better results)\n",
    "    return \"Male\" if np.random.rand() > 0.5 else \"Female\"\n",
    "\n",
    "# Step 3: Facial embeddings for identity recognition\n",
    "# Simple embedding generator (replace with a deep learning model like FaceNet for better accuracy)\n",
    "def generate_face_embedding(face_image):\n",
    "    return cv2.resize(face_image, (100, 100)).flatten()\n",
    "\n",
    "# Step 4: In-Memory Database for Current Session\n",
    "face_embeddings = []  # Stores face embeddings\n",
    "face_labels = []      # Stores corresponding labels (e.g., \"Person_1\")\n",
    "\n",
    "min_similarity_threshold = 0.8  # Adjust for tighter similarity checks\n",
    "\n",
    "def recognize_face(embedding):\n",
    "    for idx, db_embedding in enumerate(face_embeddings):\n",
    "        similarity = cosine_similarity(embedding.reshape(1, -1), db_embedding.reshape(1, -1))[0][0]\n",
    "        if similarity > min_similarity_threshold:\n",
    "            return face_labels[idx]\n",
    "    return None\n",
    "\n",
    "# Step 5: Capture Video and Process Faces\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "output_dir = \"captured_faces\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Press 'ESC' to quit.\")\n",
    "image_counter = 0\n",
    "max_images = 5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_region = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Predict gender\n",
    "        gender = predict_gender(face_region)\n",
    "\n",
    "        # Generate embedding for the face\n",
    "        embedding = generate_face_embedding(face_region)\n",
    "\n",
    "        # Recognize or add new face\n",
    "        identity = recognize_face(embedding)\n",
    "        if identity is None:\n",
    "            # Assign a new identity\n",
    "            identity = f\"Person_{len(face_embeddings) + 1}\"\n",
    "            face_embeddings.append(embedding)\n",
    "            face_labels.append(identity)\n",
    "            print(f\"New person detected: {identity}\")\n",
    "        else:\n",
    "            print(f\"Recognized: {identity}\")\n",
    "\n",
    "        # Label the face with identity and gender\n",
    "        label = f\"{identity} ({gender})\"\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "        # Save captured images if the counter is less than max_images\n",
    "        if image_counter < max_images:\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            image_path = os.path.join(output_dir, f\"{label}_{timestamp}_{image_counter}.jpg\")\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            print(f\"Captured image: {image_path}\")\n",
    "            image_counter += 1\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            print(\"Maximum of 5 pictures taken. Exiting capture loop.\")\n",
    "            break\n",
    "\n",
    "    cv2.imshow('Gender and Identity Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27 or image_counter >= max_images:  # 'ESC' key to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94d86a-b8e2-49a5-860f-3ff2281c9f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254b873-f03e-4266-b18e-53d362aea841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
